
\chapter{Classification}
\label{ch:capitolo3}
Classification was performed on the available training set using three different algorithms: K-NN (\textit{K-Nearest Neighbours}), Naïve Bayes and Decision Trees.
For K-NN \textbf{and Naïve Bayes}, a portion of the training set (referred to as the validation set) was used to select the best hyperparameters \textbf{each} model.
The features used in K-NN and Naïve Bayes were normalized, as these models are sensitive to unscaled values.
In particular, a log-transformation and \textbf{SCRIVERE SE StandardScaler O MINMAX} were applied to data.
After training, the models were evaluated on the test set using standard performance metrics. 
The target variables chosen for this task are 2: \texttt{titleType}, and \texttt{has\_LowEngagement}.
These will be discussed in more detail in the corresponding sections below.

\section{Binary classification}\label{sec:binary_classification}
The binary target variable used in this task, \texttt{has\_LowEngagement}, was specifically defined for this purpose. 
It identifies records where the \texttt{numVotes} attribute is less than 100.
\subsection*{K-NN}
\subsection*{Naïve Bayes}
\subsection*{Decision Trees}
\begin{table}[h!]
    \centering
    \caption{Classification report for binary classification (\texttt{has\_LowEngagement})}
    \begin{tabular}{lcccc}
        \toprule
        \bf{Class} & \bf{Precision} & \bf{Recall} & \bf{F1-score} & \bf{Support} \\
        \midrule
        \bf{Low engagement} & 0.86 & 0.91 & 0.88 & 3686 \\
        \bf{High engagement} & 0.78 & 0.66 & 0.72 & 1698 \\
        \midrule
        \bf{Macro avg} & 0.82 & 0.79 & 0.80 & 5384 \\
        \bf{Weighted avg} & 0.83 & 0.83 & 0.83 & 5384 \\
        \midrule
        \bf{Accuracy}  &  &  & 0.83 & 5384 \\
        \bottomrule
    \end{tabular}
    \label{tab:binary_classification_report}
\end{table}


\section{Multiclass classification}\label{sec:multiclass_classification}
Among the multiclass features of the training set, \texttt{titleType} 
was chosen as the target variable for this task due to its relevance in the dataset.\\
An important aspect to highlight is the usage of \texttt{fill\_runtimeMinutes\_notitleType}
as one of the variables to train the models. 
This feature was created to impute the missing values of the original \texttt{runtimeMinutes} variable,
but without using the median value according to the titleType. Instead, the missing values were imputed using the help of two variables: \texttt{canHaveEpisodes} and \texttt{is\_Short}
(as one of the resulting variables of the multi-label one-hot encoding process of the \texttt{genres} attribute).
In particular, 
\textbf{SCRIVERE COME E' STATA IMPUTATA NO\_TT - con canhaveepisodes e is\_short preso dai generi}.
This approach prevents a significant error, as it would be methodologically incorrect to use \texttt{titleType}-based 
imputation for an attribute when \texttt{titleType} itself is the target variable to predict.
\subsection*{K-NN}
\subsection*{Naïve Bayes}
\subsection*{Decision Trees}
\begin{table}[h!]
    \centering
    \caption{Classification report for multiclass classification (\texttt{titleType})}
    \begin{tabular}{lcccc}
        \toprule
        \bf{Class} & \bf{Precision} & \bf{Recall} & \bf{F1-score} & \bf{Support} \\
        \midrule
        \bf{movie}         & 0.85 & 0.88 & 0.87 & 1877 \\
        \bf{short}         & 0.92 & 0.94 & 0.93 & 766 \\
        \bf{tvEpisode}     & 0.89 & 0.92 & 0.90 & 1599 \\
        \bf{tvMiniSeries}  & 0.51 & 0.35 & 0.41 & 81 \\
        \bf{tvMovie}       & 0.36 & 0.29 & 0.32 & 299 \\
        \bf{tvSeries}      & 0.89 & 0.94 & 0.91 & 447 \\
        \bf{tvShort}       & 0.00 & 0.00 & 0.00 & 16 \\
        \bf{tvSpecial}     & 0.32 & 0.12 & 0.18 & 49 \\
        \bf{video}         & 0.55 & 0.46 & 0.50 & 250 \\
        \midrule
        \bf{Macro avg}     & 0.59 & 0.54 & 0.56 & 5384 \\
        \bf{Weighted avg}  & 0.82 & 0.84 & 0.83 & 5384 \\
        \midrule
        \bf{Accuracy}      &      &      & 0.84 & 5384 \\
        \bottomrule
    \end{tabular}
    \label{tab:multiclass_classification_report}
\end{table}




\section{General considerations}\label{sec:general_considerations}
